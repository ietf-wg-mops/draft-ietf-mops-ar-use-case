<!DOCTYPE html>
<html lang="en" class="Internet-Draft">
<head>
<meta charset="utf-8">
<meta content="Common,Latin" name="scripts">
<meta content="initial-scale=1.0" name="viewport">
<title>Media Operations Use Case for an Extended Reality Application on Edge Computing Infrastructure</title>
<meta content="Renan Krishna" name="author">
<meta content="Akbar Rahman" name="author">
<meta content="
       
 
 
 
 This document explores the issues involved in the use of Edge Computing resources to operationalize media use cases
 that involve Extended Reality (XR) applications. In particular, we discuss those applications that run on devices having different
 form factors and need Edge computing resources to mitigate the effect of problems such as a need to support interactive communication
 requiring low latency, limited battery power, and heat dissipation from those devices. The intended audience for this document are network
 operators who are interested in providing edge computing resources to operationalize the requirements of such applications.
 We discuss the expected behavior of XR applications which can be used to manage the traffic.
 In addition, we discuss the service requirements of XR applications to be able to run on the network.
 
       
    " name="description">
<meta content="xml2rfc 3.20.0" name="generator">
<meta content="draft-ietf-mops-ar-use-case-latest" name="ietf.draft">
<!-- Generator version information:
  xml2rfc 3.20.0
    Python 3.11.8
    ConfigArgParse 1.7
    google-i18n-address 3.1.0
    intervaltree 3.1.0
    Jinja2 3.1.2
    lxml 4.9.3
    platformdirs 4.2.0
    pycountry 22.3.5
    PyYAML 6.0.1
    requests 2.31.0
    setuptools 68.2.2
    six 1.16.0
    wcwidth 0.2.13
-->
<link href="draft-ietf-mops-ar-use-case.xml" rel="alternate" type="application/rfc+xml">
<link href="#copyright" rel="license">
<style type="text/css">@font-face {
  font-family: 'Lora';
  font-style: italic;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Italic'), local('Lora-Italic'), url('https://martinthomson.github.io/rfc-css/fonts/lora-italic-cyrillic-ext.woff2') format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
@font-face {
  font-family: 'Lora';
  font-style: italic;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Italic'), local('Lora-Italic'), url('https://martinthomson.github.io/rfc-css/fonts/lora-italic-cyrillic-ext.woff2') format('woff2');
  unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
@font-face {
  font-family: 'Lora';
  font-style: italic;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Italic'), local('Lora-Italic'), url('https://martinthomson.github.io/rfc-css/fonts/lora-italic-vietnamese.woff2') format('woff2');
  unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}
@font-face {
  font-family: 'Lora';
  font-style: italic;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Italic'), local('Lora-Italic'), url('https://martinthomson.github.io/rfc-css/fonts/lora-italic-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}

@font-face {
  font-family: 'Lora';
  font-style: italic;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Italic'), local('Lora-Italic'), url('https://martinthomson.github.io/rfc-css/fonts/lora-italic-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Regular'), local('Lora-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/lora-regular-cyrillic-ext.woff2') format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Regular'), local('Lora-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/lora-regular-cyrillic.woff2') format('woff2');
  unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Regular'), local('Lora-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/lora-regular-vietnamese.woff2') format('woff2');
  unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Regular'), local('Lora-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/lora-regular-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Regular'), local('Lora-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/lora-regular-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: local('Lora Bold'), local('Lora-Bold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-bold-cyrillic-ext.woff2') format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: local('Lora Bold'), local('Lora-Bold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-bold-cyrillic.woff2') format('woff2');
  unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: local('Lora Bold'), local('Lora-Bold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-bold-vietnamese.woff2') format('woff2');
  unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: local('Lora Bold'), local('Lora-Bold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-bold-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: local('Lora Bold'), local('Lora-Bold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-bold-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 600;
  font-display: swap;
  src: local('Lora SemiBold'), local('Lora-SemiBold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-semibold-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

@font-face {
  font-family: 'Cabin Condensed';
  font-style: normal;
  font-weight: 600;
  font-display: swap;
  src: local('Cabin Condensed SemiBold'), local('CabinCondensed-SemiBold'), url('https://martinthomson.github.io/rfc-css/fonts/cabincondensed-semibold-vietnamese.woff2') format('woff2');
  unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}
@font-face {
  font-family: 'Cabin Condensed';
  font-style: normal;
  font-weight: 600;
  font-display: swap;
  src: local('Cabin Condensed SemiBold'), local('CabinCondensed-SemiBold'), url('https://martinthomson.github.io/rfc-css/fonts/cabincondensed-semibold-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
@font-face {
  font-family: 'Cabin Condensed';
  font-style: normal;
  font-weight: 600;
  font-display: swap;
  src: local('Cabin Condensed SemiBold'), local('CabinCondensed-SemiBold'), url('https://martinthomson.github.io/rfc-css/fonts/cabincondensed-semibold-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

@font-face {
  font-family: 'Oxygen Mono';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Oxygen Mono'), local('OxygenMono-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/oxygenmono-regular-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
@font-face {
  font-family: 'Oxygen Mono';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Oxygen Mono'), local('OxygenMono-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/oxygenmono-regular-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

:root {
  color-scheme: light dark;
  --background-color: #fff;
  --text-color: #222;
  --title-color: #191919;
  --link-color: #2a6496;
  --highlight-color: #f9f9f9;
  --line-color: #eee;
  --pilcrow-weak: #ddd;
  --pilcrow-strong: #bbb;
  --small-font-size: 14.5px;
  --font-mono: 'Oxygen Mono', monospace;
  scrollbar-color: #bbb #eee;
}
body {
  max-width: 600px;
  margin: 75px auto;
  padding: 0 5px;
  color: var(--text-color);
  background-color: var(--background-color);
  font: 16px/22px "Lora", serif;
  scroll-behavior: smooth;
}

.ears {
  display: none;
}

/* headings */
h1, h2, h3, h4, h5, h6 {
  font-family: "Cabin Condensed", sans-serif;
  font-weight: 600;
  margin: 0.8em 0 0.3em;
  font-size-adjust: 0.5;
  color: var(--title-color);
}
h1#title {
  font-size: 32px;
  line-height: 40px;
  clear: both;
}
h1#title, h1#rfcnum {
  margin: 1.5em 0 0.2em;
}
h1#rfcnum + h1#title {
  margin: 0.2em 0;
}

h1, h2, h3 {
  font-size: 22px;
  line-height: 27px;
}
h4, h5, h6 {
  font-size: 20px;
  line-height: 24px;
}

/* general structure */
.author {
  padding-bottom: 0.3em;
}
#abstract+p {
  font-size: 18px;
  line-height: 24px;
}
#abstract+p code, #abstract+p samp, #abstract+p tt {
  font-size: 16px;
  line-height: 0;
}

p {
  padding: 0;
  margin: 0.5em 0;
  text-align: left;
}
div {
  margin: 0;
}
.alignRight.art-text {
  background-color: var(--highlight-color);
  border: 1px solid var(--line-color);
  border-radius: 3px;
  padding: 0.5em 1em 0;
  margin-bottom: 0.5em;
}
.alignRight.art-text pre {
  padding: 0;
  width: auto;
}
.alignRight {
  margin: 1em 0;
}
.alignRight > *:first-child {
  border: none;
  margin: 0;
  float: right;
  clear: both;
}
.alignRight > *:nth-child(2) {
  clear: both;
  display: block;
  border: none;
}
svg {
  display: block;
}
/* font-family isn't space-separated, but =~ will have to do */
svg[font-family~="monospace" i], svg [font-family~="monospace" i] {
  font-family: var(--font-mono);
}
.alignCenter.art-text {
  background-color: var(--highlight-color);
  border: 1px solid var(--line-color);
  border-radius: 3px;
  padding: 0.5em 1em 0;
  margin-bottom: 0.5em;
}
.alignCenter.art-text pre {
  padding: 0;
  width: auto;
}
.alignCenter {
  margin: 1em 0;
}
.alignCenter > *:first-child {
  border: none;
  /* this isn't optimal, but it's an existence proof.  PrinceXML doesn't
     support flexbox yet.
  */
  display: table;
  margin: 0 auto;
}

/* lists */
ol, ul {
  padding: 0;
  margin: 0 0 0.5em 2em;
}
:is(ol, ul) :is(ol, ul) {
  margin-left: 1em;
}
li {
  margin: 0 0 0.25em 0;
}
.ulCompact li {
  margin: 0;
}
ul.empty, .ulEmpty {
  list-style-type: none;
}
ul.empty li, .ulEmpty li {
  margin-top: 0.5em;
}
:is(ul, ol).compact, .ulCompact, .olCompact {
  line-height: 1;
  margin: 0 0 0 2em;
}

/* definition lists */
dl {
  clear: left;
  --indent: 3ch;
  /* --indent: attr(indent ch); not supported in any browser, but we can dream */
}
dl.olPercent {
  --indent: 5ch;
}
dl > dt {
  float: left;
  margin-right: 2ch;
  min-width: 8ch;
}
dl.dlNewline > dt {
  float: none;
}
dl > dd {
  margin-bottom: .8em;
  margin-left: var(--indent) !important; /* stupid element overrides */
  min-height: 2ex;
}
dl.olPercent > dt {
  min-width: calc(var(--indent) - 2ch);
}
:is(dl.compact, .dlCompact) > dd {
  margin-bottom: 0;
}
:is(dl.compact, .dlCompact) > dd > :is(:first-child, .break:first-child + *) {
  margin-top: 0;
}
:is(dl.compact, .dlCompact) > dd > :is(:last-child) {
  margin-bottom: 0;
}
dl > dd > dl {
  margin-top: 0.5em;
  margin-bottom: 0;
}
:is(dd, span).break {
  display: none;
}

/* links */
a, a[href].selfRef:hover {
  text-decoration: none;
}
a[href] {
  color: var(--link-color);
}
a[href].selfRef, .iref + a[href].internal {
  color: var(--text-color);
}
a[href]:hover {
  text-decoration: underline;
}
a[href].selfRef:hover {
  background-color: var(--highlight-color);
}
a.xref:is(.cite, .auto), :is(#status-of-memo, #copyright) a {
  white-space: nowrap;
}

/* Figures */
tt, code, pre {
  background-color: var(--highlight-color);
  font: 14px/22px var(--font-mono);
}
tt, code {
  /* changing the font for inline elements leads to different ascender
     and descender heights; as we want to retain baseline alignment,
     remove leading to avoid altering the final height of lines
     note: this fails if these blocks take an entire line,
     a different solution would be great */
  line-height: 0;
}
:is(h1, h2, h3, h4, h5, h6) :is(tt, code) {
  font-size: 84%;
}
pre {
  border: 1px solid var(--line-color);
  font-size: 13.5px;
  line-height: 16px;
  letter-spacing: -0.2px;
  margin: 5px;
  padding: 5px;
}
img {
  max-width: 100%;
}
figure {
  margin: 0.5em 0;
  padding: 0;
}
figure blockquote {
  margin: 0.8em 0.4em 0.4em;
}
figcaption, caption {
  font-style: italic;
  margin: 0.5em 1.5em;
  text-align: left;
}
@media screen {
  /* Auto-collapse boilerplate. */
  :is(#status-of-memo, #copyright) p {
    margin: -2px 0;
    max-height: 0;
    transition: max-height 2s ease, margin 0.5s ease 0.5s;
    overflow: hidden;
  }
  :is(#status-of-memo, #copyright):hover p,
  :is(#status-of-memo, #copyright) h2:target ~ p {
    margin: 0.5em 0;
    max-height: 500px;
    overflow: auto;
  }
  pre, svg {
    display: inline-block;
    overflow-x: auto;
  }
  pre {
    max-width: 100%;
    width: calc(100% - 22px - 1em);
  }
  svg {
    max-width: calc(100% - 22px - 1em);
  }
  figure pre {
    display: block;
    width: calc(100% - 25px);
  }
  :is(pre, svg) + .pilcrow {
    display: inline-block;
    vertical-align: text-bottom;
    padding-bottom: 8px;
  }
}

/* aside, blockquote */
aside, blockquote {
  margin-left: 0;
  padding: 0 2em;
  font-style: italic;
}
blockquote {
  margin: 1em 0;
}
cite {
  display: block;
  text-align: right;
  font-style: italic;
}

/* tables */
table {
  max-width: 100%;
  margin: 0 0 1em;
  border-collapse: collapse;
}
table.right {
  margin-left: auto;
}
table.center {
  margin-left: auto;
  margin-right: auto;
}
table.left {
  margin-right: auto;
}
thead, tbody {
  border: 1px solid var(--line-color);
}
th, td {
  text-align: left;
  vertical-align: top;
  padding: 5px 10px;
}
th {
  background-color: var(--line-color);
}
:is(tr:nth-child(2n), thead+tbody > tr:nth-child(2n+1)) > td {
  background-color: var(--background-color);
}
:is(tr:nth-child(2n+1), thead+tbody > tr:nth-child(2n)) > td {
  background-color: var(--highlight-color);
}
table caption {
  margin: 0;
  padding: 3px 0 3px 1em;
}
table p {
  margin: 0;
}

/* pilcrow */
a.pilcrow {
  margin-left: 3px;
  opacity: 0.2;
  user-select: none;
}
a.pilcrow[href] { color: var(--pilcrow-weak); }
a.pilcrow[href]:hover { text-decoration: none; }
@media not print {
  :hover > a.pilcrow {
    opacity: 1;
  }
  a.pilcrow[href]:hover {
    color: var(--pilcrow-strong);
    background-color: transparent;
  }
}
@media print {
  a.pilcrow {
    display: none;
  }
}

/* misc */
hr {
  border: 0;
  border-top: 1px solid var(--line-color);
}
.bcp14 {
  font-variant: small-caps;
  font-weight: 600;
  font-size: var(--small-font-size);
}
.role {
  font-variant: all-small-caps;
}
sub, sup {
  line-height: 1;
  font-size: 80%;
}

/* info block */
#identifiers {
  margin: 0;
  font-size: var(--small-font-size);
  line-height: 18px;
  --identifier-width: 15ch;
}
#identifiers dt {
  width: var(--identifier-width);
  min-width: var(--identifier-width);
  clear: left;
  float: left;
  text-align: right;
  margin-right: 1ch;
}
#identifiers dd {
  margin: 0;
  margin-left: calc(1em + var(--identifier-width)) !important;
  min-width: 5em;
}
#identifiers .authors .author {
  display: inline-block;
  margin-right: 1.5em;
}
#identifiers .authors .org {
  font-style: italic;
}

/* The prepared/rendered info at the very bottom of the page */
.docInfo {
  color: #999;
  font-size: 0.9em;
  font-style: italic;
  margin-top: 2em;
}
.docInfo .prepared {
  float: left;
}
.docInfo .prepared {
  float: right;
}

/* table of contents */
#toc {
  padding: 0.75em 0 2em 0;
  margin-bottom: 1em;
}
#toc nav ul {
  margin: 0 0.5em 0 0;
  padding: 0;
  list-style: none;
}
#toc nav li {
  line-height: 1.3em;
  margin: 2px 0;
  padding-left: 1.2em;
  text-indent: -1.2em;
}
#toc a.xref {
  white-space: normal;
}
/* references */
.references dt {
  text-align: right;
  font-weight: bold;
  min-width: 10ch;
  margin-right: 1.5ch;
}
.references dt:target::before {
  content: "⇒";
  width: 15px;
  margin: 0 10px 0 -25px;
}
.references dd {
  margin-left: 12ch !important;
  overflow: auto;
}

.refInstance {
  margin-bottom: 1.25em;
}

.references .ascii {
  margin-bottom: 0.25em;
}

/* index */
#rfc\.index\.index + ul {
  margin-left: 0;
}

/* authors */
address.vcard {
  font-style: normal;
  margin: 1em 0;
}
address.vcard .nameRole {
  font-weight: 700;
  margin-left: 0;
}
address.vcard .label {
  margin: 0.5em 0;
}
address.vcard .type {
  display: none;
}
.alternative-contact {
  margin: 1.5em 0 1em;
}
hr.addr {
  border-top: 1px dashed;
  margin: 0;
  color: #ddd;
  max-width: calc(100% - 16px);
}
@media (min-width: 500px) {
  #authors-addresses > section {
    column-count: 2;
    column-gap: 20px;
  }
  #authors-addresses > section > h2 {
    column-span: all;
  }
  /* hack for break-inside: avoid-column */
  #authors-addresses address {
    display: inline-block;
    break-inside: avoid-column;
  }
}

.rfcEditorRemove p:first-of-type {
  font-style: italic;
}
.cref {
  background-color: rgba(249, 232, 105, 0.3);
  padding: 2px 4px;
}
.crefSource {
  font-style: italic;
}
/* alternative layout for smaller screens */
@media screen and (max-width: 929px) {
  #toc {
    position: fixed;
    z-index: 2;
    top: 0;
    right: 0;
    padding: 1px 0 0 0;
    margin: 0;
    border-bottom: 1px solid #ccc;
    opacity: 0.6;
  }
  #toc.active {
      opacity: 1;
  }
  #toc h2 {
    margin: 0;
    padding: 2px 0 2px 6px;
    padding-right: 1em;
    font-size: 18px;
    line-height: 24px;
    min-width: 190px;
    text-align: right;
    background-color: #444;
    color: white;
    cursor: pointer;
  }
  #toc h2::before { /* css hamburger */
    float: right;
    position: relative;
    width: 1em;
    height: 1px;
    left: -164px;
    margin: 8px 0 0 0;
    background: white none repeat scroll 0 0;
    box-shadow: 0 4px 0 0 white, 0 8px 0 0 white;
    content: "";
  }
  #toc nav {
    display: none;
    background-color: var(--background-color);
    padding: 0.5em 1em 1em;
    overflow: auto;
    overscroll-behavior: contain;
    height: calc(100vh - 48px);
    border-left: 1px solid #ddd;
  }
  #toc.active nav {
    display: block;
  }
  /* Make the collapsed ToC header render white on gray also when it's a link */
  #toc h2 a,
  #toc h2 a:link,
  #toc h2 a:focus,
  #toc h2 a:hover,
  #toc a.toplink,
  #toc a.toplink:hover {
    color: white;
    background-color: #444;
    text-decoration: none;
  }
  #toc a.toplink {
    margin-top: 2px;
  }
}

/* alternative layout for wide screens */
@media screen and (min-width: 930px) {
  body {
    padding-right: 360px;
    padding-right: calc(min(180px + 20%, 500px));
  }
  #toc {
    position: fixed;
    bottom: 0;
    right: 0;
    right: calc(50vw - 480px);
    width: 312px;
    margin: 0;
    padding: 0;
    z-index: 1;
  }
  #toc h2 {
    margin: 0;
    padding: 0.25em 1em 1em 0;
  }
  #toc nav {
    display: block;
    height: calc(90vh - 84px);
    bottom: 0;
    padding: 0.5em 0 2em;
    overflow: auto;
    overscroll-behavior: contain;
    scrollbar-width: thin;
  }
  #toc nav > ul  {
    margin-bottom: 2em;
  }
  #toc ul {
    margin: 0 0 0 4px;
    font-size: var(--small-font-size);
  }
  #toc ul :is(p, li) {
    margin: 2px 0;
    line-height: 22px;
  }
  img { /* future proofing */
    max-width: 100%;
    height: auto;
  }
}

/* pagination */
@media print {
  body {
    width: 100%;
  }
  p {
    orphans: 3;
    widows: 3;
  }
  #n-copyright-notice {
    border-bottom: none;
  }
  #toc, #n-introduction {
    page-break-before: always;
  }
  #toc {
    border-top: none;
    padding-top: 0;
  }
  figure, pre, .vcard {
    page-break-inside: avoid;
  }
  h1, h2, h3, h4, h5, h6 {
    page-break-after: avoid;
  }
  :is(h2, h3, h4, h5, h6)+*, dd {
    page-break-before: avoid;
  }
  pre {
    white-space: pre-wrap;
    word-wrap: break-word;
    font-size: 10pt;
  }
  table {
    border: 1px solid #ddd;
  }
  td {
    border-top: 1px solid #ddd;
  }
  .toplink {
    display: none;
  }
}

@page :first {
  padding-top: 0;
  @top-left {
    content: normal;
    border: none;
  }
  @top-center {
    content: normal;
    border: none;
  }
  @top-right {
    content: normal;
    border: none;
  }
}

@page {
  size: A4;
  margin-bottom: 45mm;
  padding-top: 20px;
}

/* Changes introduced to fix issues found during implementation */

/* Separate body from document info even without intervening H1 */
section {
  clear: both;
}

/* Top align author divs, to avoid names without organization dropping level with org names */
.author {
  vertical-align: top;
}

/* Style section numbers with more space between number and title */
.section-number {
  padding-right: 0.5em;
}

/* Add styling for a link in the ToC that points to the top of the document */
a.toplink {
  float: right;
  margin: 8px 0.5em 0;
}

/* Provide styling for table cell text alignment */
table .text-left {
  text-align: left;
}
table .text-center {
  text-align: center;
}
table .text-right {
  text-align: right;
}

/* Make the alternative author contact information look less like just another
   author, and group it closer with the primary author contact information */
.alternative-contact {
  margin: 0.5em 0 0.25em 0;
}
address .non-ascii {
  margin: 0 0 0 2em;
}

/* With it being possible to set tables with alignment
  left, center, and right, { width: 100%; } does not make sense */
table {
  width: auto;
}

/* Avoid reference text that sits in a block with very wide left margin,
   because of a long floating dt label.*/
.references dd {
  overflow: visible;
}

/* Control caption placement */
caption {
  caption-side: bottom;
}

/* Limit the width of the author address vcard, so names in right-to-left
   script don't end up on the other side of the page. */

address.vcard {
  max-width: 20em;
  margin-right: auto;
}

/* For address alignment dependent on LTR or RTL scripts */
address div.left {
  text-align: left;
}
address div.right {
  text-align: right;
}

/* Dark mode. */
@media (prefers-color-scheme: dark) {
:root {
  --background-color: #121212;
  --text-color: #f0f0f0;
  --title-color: #fff;
  --link-color: #4da4f0;
  --highlight-color: #282828;
  --line-color: #444;
  --pilcrow-weak: #444;
  --pilcrow-strong: #666;
  scrollbar-color: #777 #333;
}
}

/* SVG Trick: a prefix match works because only black and white are allowed */
svg :is([stroke="black"], [stroke^="#000"]) {
  stroke: var(--text-color);
}
svg :is([stroke="white"], [stroke^="#fff"]) {
  stroke: var(--background-color);
}
svg :is([fill="black"], [fill^="#000"], :not([fill])) {
  fill: var(--text-color);
}
svg :is([fill="white"], [fill^="#fff"]) {
  fill: var(--background-color);
}
</style>

</head>
<body class="xml2rfc">
<table class="ears">
<thead><tr>
<td class="left">Internet-Draft</td>
<td class="center">MOPS AR Use Case</td>
<td class="right">March 2024</td>
</tr></thead>
<tfoot><tr>
<td class="left">Krishna &amp; Rahman</td>
<td class="center">Expires 5 September 2024</td>
<td class="right">[Page]</td>
</tr></tfoot>
</table>
<div id="external-metadata" class="document-information"></div>
<div id="internal-metadata" class="document-information">
<dl id="identifiers">
<dt class="label-workgroup">Workgroup:</dt>
<dd class="workgroup">MOPS</dd>
<dt class="label-internet-draft">Internet-Draft:</dt>
<dd class="internet-draft">draft-ietf-mops-ar-use-case-latest</dd>
<dt class="label-published">Published:</dt>
<dd class="published">
<time datetime="2024-03-04" class="published">4 March 2024</time>
    </dd>
<dt class="label-intended-status">Intended Status:</dt>
<dd class="intended-status">Informational</dd>
<dt class="label-expires">Expires:</dt>
<dd class="expires"><time datetime="2024-09-05">5 September 2024</time></dd>
<dt class="label-authors">Authors:</dt>
<dd class="authors">
<div class="author">
      <div class="author-name">R. Krishna</div>
<div class="org">InterDigital Europe Limited</div>
</div>
<div class="author">
      <div class="author-name">A. Rahman</div>
<div class="org">Ericsson</div>
</div>
</dd>
</dl>
</div>
<h1 id="title">Media Operations Use Case for an Extended Reality Application on Edge Computing Infrastructure</h1>
<section id="section-abstract">
      <h2 id="abstract"><a href="#abstract" class="selfRef">Abstract</a></h2>
<p id="section-abstract-1">
 
 
 
 This document explores the issues involved in the use of Edge Computing resources to operationalize media use cases
 that involve Extended Reality (XR) applications. In particular, we discuss those applications that run on devices having different
 form factors and need Edge computing resources to mitigate the effect of problems such as a need to support interactive communication
 requiring low latency, limited battery power, and heat dissipation from those devices. The intended audience for this document are network
 operators who are interested in providing edge computing resources to operationalize the requirements of such applications.
 We discuss the expected behavior of XR applications which can be used to manage the traffic.
 In addition, we discuss the service requirements of XR applications to be able to run on the network.<a href="#section-abstract-1" class="pilcrow">¶</a></p>
</section>
<div id="status-of-memo">
<section id="section-boilerplate.1">
        <h2 id="name-status-of-this-memo">
<a href="#name-status-of-this-memo" class="section-name selfRef">Status of This Memo</a>
        </h2>
<p id="section-boilerplate.1-1">
        This Internet-Draft is submitted in full conformance with the
        provisions of BCP 78 and BCP 79.<a href="#section-boilerplate.1-1" class="pilcrow">¶</a></p>
<p id="section-boilerplate.1-2">
        Internet-Drafts are working documents of the Internet Engineering Task
        Force (IETF). Note that other groups may also distribute working
        documents as Internet-Drafts. The list of current Internet-Drafts is
        at <span><a href="https://datatracker.ietf.org/drafts/current/">https://datatracker.ietf.org/drafts/current/</a></span>.<a href="#section-boilerplate.1-2" class="pilcrow">¶</a></p>
<p id="section-boilerplate.1-3">
        Internet-Drafts are draft documents valid for a maximum of six months
        and may be updated, replaced, or obsoleted by other documents at any
        time. It is inappropriate to use Internet-Drafts as reference
        material or to cite them other than as "work in progress."<a href="#section-boilerplate.1-3" class="pilcrow">¶</a></p>
<p id="section-boilerplate.1-4">
        This Internet-Draft will expire on 5 September 2024.<a href="#section-boilerplate.1-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="copyright">
<section id="section-boilerplate.2">
        <h2 id="name-copyright-notice">
<a href="#name-copyright-notice" class="section-name selfRef">Copyright Notice</a>
        </h2>
<p id="section-boilerplate.2-1">
            Copyright (c) 2024 IETF Trust and the persons identified as the
            document authors. All rights reserved.<a href="#section-boilerplate.2-1" class="pilcrow">¶</a></p>
<p id="section-boilerplate.2-2">
            This document is subject to BCP 78 and the IETF Trust's Legal
            Provisions Relating to IETF Documents
            (<span><a href="https://trustee.ietf.org/license-info">https://trustee.ietf.org/license-info</a></span>) in effect on the date of
            publication of this document. Please review these documents
            carefully, as they describe your rights and restrictions with
            respect to this document. Code Components extracted from this
            document must include Revised BSD License text as described in
            Section 4.e of the Trust Legal Provisions and are provided without
            warranty as described in the Revised BSD License.<a href="#section-boilerplate.2-2" class="pilcrow">¶</a></p>
</section>
</div>
<div id="toc">
<section id="section-toc.1">
        <a href="#" onclick="scroll(0,0)" class="toplink">▲</a><h2 id="name-table-of-contents">
<a href="#name-table-of-contents" class="section-name selfRef">Table of Contents</a>
        </h2>
<nav class="toc"><ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.1">
            <p id="section-toc.1-1.1.1" class="keepWithNext"><a href="#section-1" class="auto internal xref">1</a>.  <a href="#name-introduction" class="internal xref">Introduction</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2">
            <p id="section-toc.1-1.2.1" class="keepWithNext"><a href="#section-2" class="auto internal xref">2</a>.  <a href="#name-conventions-used-in-this-do" class="internal xref">Conventions used in this document</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3">
            <p id="section-toc.1-1.3.1"><a href="#section-3" class="auto internal xref">3</a>.  <a href="#name-use-case" class="internal xref">Use Case</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.1">
                <p id="section-toc.1-1.3.2.1.1" class="keepWithNext"><a href="#section-3.1" class="auto internal xref">3.1</a>.  <a href="#name-processing-of-scenes" class="internal xref">Processing of Scenes</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.2">
                <p id="section-toc.1-1.3.2.2.1"><a href="#section-3.2" class="auto internal xref">3.2</a>.  <a href="#name-generation-of-images" class="internal xref">Generation of Images</a></p>
</li>
            </ul>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.4">
            <p id="section-toc.1-1.4.1"><a href="#section-4" class="auto internal xref">4</a>.  <a href="#name-requirements" class="internal xref">Requirements</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5">
            <p id="section-toc.1-1.5.1"><a href="#section-5" class="auto internal xref">5</a>.  <a href="#name-ar-network-traffic" class="internal xref">AR Network Traffic</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.1">
                <p id="section-toc.1-1.5.2.1.1"><a href="#section-5.1" class="auto internal xref">5.1</a>.  <a href="#name-traffic-workload" class="internal xref">Traffic Workload</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.2">
                <p id="section-toc.1-1.5.2.2.1"><a href="#section-5.2" class="auto internal xref">5.2</a>.  <a href="#name-traffic-performance-metrics" class="internal xref">Traffic Performance Metrics</a></p>
</li>
            </ul>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.6">
            <p id="section-toc.1-1.6.1"><a href="#section-6" class="auto internal xref">6</a>.  <a href="#name-iana-considerations" class="internal xref">IANA Considerations</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.7">
            <p id="section-toc.1-1.7.1"><a href="#section-7" class="auto internal xref">7</a>.  <a href="#name-security-considerations" class="internal xref">Security Considerations</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.8">
            <p id="section-toc.1-1.8.1"><a href="#section-8" class="auto internal xref">8</a>.  <a href="#name-acknowledgements" class="internal xref">Acknowledgements</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.9">
            <p id="section-toc.1-1.9.1"><a href="#section-9" class="auto internal xref">9</a>.  <a href="#name-informative-references" class="internal xref">Informative References</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.10">
            <p id="section-toc.1-1.10.1"><a href="#appendix-A" class="auto internal xref"></a><a href="#name-authors-addresses" class="internal xref">Authors' Addresses</a></p>
</li>
        </ul>
</nav>
</section>
</div>
<div id="introduction">
<section id="section-1">
      <h2 id="name-introduction">
<a href="#section-1" class="section-number selfRef">1. </a><a href="#name-introduction" class="section-name selfRef">Introduction</a>
      </h2>
<p id="section-1-1">
 Extended Reality (XR) is a term that includes Augmented Realty (AR), Virtual Reality (VR) and Mixed Realty (MR) <span>[<a href="#XR" class="cite xref">XR</a>]</span>.
 AR combines the real and virtual, is interactive and is aligned to the physical world of the user <span>[<a href="#AUGMENTED_2" class="cite xref">AUGMENTED_2</a>]</span>. On the other hand,
 VR places the user inside a virtual environment generated by a computer <span>[<a href="#AUGMENTED" class="cite xref">AUGMENTED</a>]</span>.MR merges the real and virtual world along a
 continuum that connects completely real environment at one end to a completely virtual environment at the other end. In this continuum, all
 combinations of the real and virtual are captured <span>[<a href="#AUGMENTED" class="cite xref">AUGMENTED</a>]</span>.<a href="#section-1-1" class="pilcrow">¶</a></p>
<p id="section-1-2">
     XR applications will bring several requirements for the network and the
 mobile devices running these applications. Some XR applications such as AR require a real-time processing of video streams to
 recognize specific objects. This is then used to overlay information on the
 video being displayed to the user.  In addition XR applications such as AR and VR will also require generation of new video
 frames to be played to the user. Both the real-time processing of video streams and the generation of overlay information
 are computationally intensive tasks that generate heat <span>[<a href="#DEV_HEAT_1" class="cite xref">DEV_HEAT_1</a>]</span>, <span>[<a href="#DEV_HEAT_2" class="cite xref">DEV_HEAT_2</a>]</span>
 and drain battery power <span>[<a href="#BATT_DRAIN" class="cite xref">BATT_DRAIN</a>]</span> on the mobile device running the XR application.
 Consequently, in order to run applications with XR characteristics
 on mobile devices, computationally intensive tasks need to be offloaded to resources provided by Edge Computing.<a href="#section-1-2" class="pilcrow">¶</a></p>
<p id="section-1-3">
 Edge Computing is an emerging paradigm where computing resources and storage are made available in close
 network proximity at the edge of the Internet to mobile devices and sensors <span>[<a href="#EDGE_1" class="cite xref">EDGE_1</a>]</span>, <span>[<a href="#EDGE_2" class="cite xref">EDGE_2</a>]</span>.
 These edge computing devices use cloud technologies that enable them to support offloaded XR applications. In particular, the edge devices deploy
 cloud computing implementation techniques such as disaggregation (breaking vertically integrated systems into independent components with open interfaces
 using SDN), virtualization (being able to run multiple independent copies of those components such as SDN Controller apps, Virtual Network Functions on a
 common hardware platform) and commoditization ( being able to elastically scale those virtual components across commodity hardware as the workload dictates)
 <span>[<a href="#EDGE_3" class="cite xref">EDGE_3</a>]</span>. Such techniques enable XR applications requiring low-latency and high bandwidth to be delivered by mini-clouds
 running on proximate edge devices<a href="#section-1-3" class="pilcrow">¶</a></p>
<p id="section-1-4">
   In this document, we discuss the issues involved when edge computing resources are offered by network operators to
   operationalize the requirements of XR applications running on devices with various form factors. Examples of such form factors
   include Head Mounted Displays (HMD) such as Optical-see through HMDs and video-see-through HMDs and Hand-held displays.
   Smart phones with video cameras and GPS are another example of such devices. These devices have limited
   battery capacity and dissipate heat when running. Besides as the user of these devices moves around as they run the
   XR application, the wireless latency and bandwidth available to the devices fluctuates and the communication link itself
   might fail. As a result algorithms such as those based on adaptive-bit-rate techniques that base their policy on heuristics
   or models of deployment perform sub-optimally in such dynamic environments<span>[<a href="#ABR_1" class="cite xref">ABR_1</a>]</span>.
   In addition, network operators can expect that the parameters that characterize the expected behavior of XR applications
   are heavy-tailed. Such workloads require appropriate resource management policies to be used on the Edge.
   The service requirements of XR applications are also challenging when compared to the current video applications.
   In particular several QoE factors such as motion sickness are unique to XR applications and must be considered when operationalizing a network.

 We motivate these issues with a use-case that we present in the following sections.<a href="#section-1-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="convention">
<section id="section-2">
      <h2 id="name-conventions-used-in-this-do">
<a href="#section-2" class="section-number selfRef">2. </a><a href="#name-conventions-used-in-this-do" class="section-name selfRef">Conventions used in this document</a>
      </h2>
<p id="section-2-1">The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
 "OPTIONAL" in this document are to be interpreted as described in <span>[<a href="#RFC2119" class="cite xref">RFC2119</a>]</span>.<a href="#section-2-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="use_case">
<section id="section-3">
      <h2 id="name-use-case">
<a href="#section-3" class="section-number selfRef">3. </a><a href="#name-use-case" class="section-name selfRef">Use Case</a>
      </h2>
<p id="section-3-1">
  We now describe a use case that involves an application with
  AR systems' characteristics. Consider a group of tourists who are being
  conducted in a tour around the historical site of the Tower of London.
  As they move around the site and within the historical buildings, they can
  watch and listen to historical scenes in 3D that are generated by the AR application and then
  overlaid by their AR headsets onto their real-world view. The headset then continuously updates their view as they move around.<a href="#section-3-1" class="pilcrow">¶</a></p>
<p id="section-3-2">
 The AR  application first processes the scene that the walking tourist is watching in real-time and identifies objects
 that will be targeted for overlay of high resolution videos. It then generates high resolution 3D images
 of historical scenes  related to the perspective of the tourist in real-time. These generated video images are then
 overlaid on the view of the real-world as seen by the tourist.<a href="#section-3-2" class="pilcrow">¶</a></p>
<p id="section-3-3">
 We now discuss this  processing of scenes
 and generation of high resolution images in greater detail.<a href="#section-3-3" class="pilcrow">¶</a></p>
<div id="processsing_of_scenes">
<section id="section-3.1">
        <h3 id="name-processing-of-scenes">
<a href="#section-3.1" class="section-number selfRef">3.1. </a><a href="#name-processing-of-scenes" class="section-name selfRef">Processing of Scenes</a>
        </h3>
<p id="section-3.1-1">
 The task of processing a scene can be broken down into a pipeline of three consecutive subtasks namely tracking, followed by an acquisition of a
 model of the real world, and finally registration <span>[<a href="#AUGMENTED" class="cite xref">AUGMENTED</a>]</span>.<a href="#section-3.1-1" class="pilcrow">¶</a></p>
<p id="section-3.1-2">
 Tracking: This includes tracking of the three dimensional coordinates and six dimensional pose (coordinates and orientation)
 of objects in the real world<span>[<a href="#AUGMENTED" class="cite xref">AUGMENTED</a>]</span>.
 The AR application that runs on the mobile device needs to track the pose
 of the user's head, eyes and the
 objects that are in view.This requires tracking natural features that are then used in the next stage of the pipeline.<a href="#section-3.1-2" class="pilcrow">¶</a></p>
<p id="section-3.1-3">
 Acquisition of a model of the real world: The tracked natural features are used to develop an annotated
 point cloud based model that is then stored in a database.To ensure that this database can be scaled up,techniques such as
 combining a client side simultaneous tracking and mapping and a server-side localization
 are used<span>[<a href="#SLAM_1" class="cite xref">SLAM_1</a>]</span>, <span>[<a href="#SLAM_2" class="cite xref">SLAM_2</a>]</span>, <span>[<a href="#SLAM_3" class="cite xref">SLAM_3</a>]</span>, <span>[<a href="#SLAM_4" class="cite xref">SLAM_4</a>]</span>.Another model that can be built is based on polygon mesh and texture mapping technique. The polygon mesh encodes a 3D object's shape which is expressed as a collection of small flat surfaces that are polygons. In texture mapping, color patterns are mapped on to an object's surface. A third modelling technique uses a 2D lightfield that describes the intensity or color of the light rays arriving at a single point from arbitrary directions. Assuming distant light sources, the single point is approximately valid for small scenes. For larger scenes, a 5D lightfield is used which encodes seperate 2D lightfields for many 3D positions in space <span>[<a href="#AUGMENTED" class="cite xref">AUGMENTED</a>]</span>.<a href="#section-3.1-3" class="pilcrow">¶</a></p>
<p id="section-3.1-4">
 Registration: The coordinate systems, brightness, and color
 of virtual and real objects need to be aligned in a process called registration <span>[<a href="#REG" class="cite xref">REG</a>]</span>.
 Once the
 natural features are tracked as discussed above, virtual objects are geometrically aligned with those features by geometric registration
 .This is followed by
 resolving occlusion that can occur between virtual and the real objects <span>[<a href="#OCCL_1" class="cite xref">OCCL_1</a>]</span>, <span>[<a href="#OCCL_2" class="cite xref">OCCL_2</a>]</span>.
 
 The AR application also applies photometric registration <span>[<a href="#PHOTO_REG" class="cite xref">PHOTO_REG</a>]</span>
 by aligning the brightness and color between the virtual and
 real objects.Additionally, algorithms that calculate global illumination of both the virtual and real objects <span>[<a href="#GLB_ILLUM_1" class="cite xref">GLB_ILLUM_1</a>]</span>,
 <span>[<a href="#GLB_ILLUM_2" class="cite xref">GLB_ILLUM_2</a>]</span> are executed.Various algorithms to deal with artifacts generated by lens distortion <span>[<a href="#LENS_DIST" class="cite xref">LENS_DIST</a>]</span>,
 blur <span>[<a href="#BLUR" class="cite xref">BLUR</a>]</span>, noise <span>[<a href="#NOISE" class="cite xref">NOISE</a>]</span> etc are also required.<a href="#section-3.1-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="generation">
<section id="section-3.2">
        <h3 id="name-generation-of-images">
<a href="#section-3.2" class="section-number selfRef">3.2. </a><a href="#name-generation-of-images" class="section-name selfRef">Generation of Images</a>
        </h3>
<p id="section-3.2-1">
 The AR application must generate a high-quality video that has the properties described in the previous step
 and overlay the video on the AR device's display- a step called situated visualization. This entails  dealing with registration errors that
 may arise, ensuring that there is no visual interference <span>[<a href="#VIS_INTERFERE" class="cite xref">VIS_INTERFERE</a>]</span>, and finally maintaining
 temporal coherence by adapting to the movement of user's eyes and head.<a href="#section-3.2-1" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
<div id="Req">
<section id="section-4">
      <h2 id="name-requirements">
<a href="#section-4" class="section-number selfRef">4. </a><a href="#name-requirements" class="section-name selfRef">Requirements</a>
      </h2>
<p id="section-4-1">
 The components of AR applications perform tasks such as real-time generation and processing of
 high-quality video content that are computationally intensive. As a result,on AR devices such as AR glasses
 excessive heat is generated by the chip-sets that are involved
 in the computation <span>[<a href="#DEV_HEAT_1" class="cite xref">DEV_HEAT_1</a>]</span>, <span>[<a href="#DEV_HEAT_2" class="cite xref">DEV_HEAT_2</a>]</span>.  Additionally,
 the battery on such devices discharges quickly when running
 such applications <span>[<a href="#BATT_DRAIN" class="cite xref">BATT_DRAIN</a>]</span>.<a href="#section-4-1" class="pilcrow">¶</a></p>
<p id="section-4-2">
 A solution to the heat dissipation and battery drainage problem is to offload the processing and video generation tasks
 to the remote cloud.However, running such tasks on the cloud is not feasible as the end-to-end delays
 must be within the order of a few milliseconds. Additionally,such applications require high bandwidth
 and low jitter to provide a high QoE to the user.In order to achieve such hard timing constraints, computationally intensive
 tasks can be offloaded to Edge devices.<a href="#section-4-2" class="pilcrow">¶</a></p>
<p id="section-4-3">
 
 Another requirement for our use case and similar applications such as 360 degree streaming is that the display on
 the AR/VR device should synchronize the visual input with the way the user is moving their head. This synchronization
 is necessary to avoid motion sickness that results from a time-lag between when the user moves their head and
 when the appropriate video scene is rendered. This time lag is often called "motion-to-photon" delay.
Studies have shown <span>[<a href="#PER_SENSE" class="cite xref">PER_SENSE</a>]</span>, <span>[<a href="#XR" class="cite xref">XR</a>]</span>, <span>[<a href="#OCCL_3" class="cite xref">OCCL_3</a>]</span> that this delay
can be at most 20ms and preferably between 7-15ms in
order to avoid the motion sickness problem. Out of these 20ms, display techniques including the refresh
rate of write displays and pixel switching take 12-13ms <span>[<a href="#OCCL_3" class="cite xref">OCCL_3</a>]</span>, <span>[<a href="#CLOUD" class="cite xref">CLOUD</a>]</span>. This leaves 7-8ms for the processing of
motion sensor inputs, graphic rendering, and RTT between the AR/VR device and the Edge.
The use of predictive techniques to mask latencies has been considered as a mitigating strategy to reduce motion sickness <span>[<a href="#PREDICT" class="cite xref">PREDICT</a>]</span>.
In addition, Edge Devices that are proximate to the user might be used to offload these computationally intensive tasks.
Towards this end, the 3GPP requires and supports an Ultra Reliable Low Latency of 0.1ms to 1ms for
communication between an Edge server and User Equipment(UE)  <span>[<a href="#URLLC" class="cite xref">URLLC</a>]</span>.<a href="#section-4-3" class="pilcrow">¶</a></p>
<p id="section-4-4">
 Note that the Edge device providing the computation and storage is itself limited in such resources compared to the Cloud.  So,
 for example, a sudden surge in demand from a large group of tourists can overwhelm that device. This will result in a degraded user
  experience as their AR device experiences delays in receiving the video frames. In order to deal
  with this problem, the client AR applications will need to use Adaptive Bit Rate (ABR) algorithms that choose bit-rates policies
  tailored in a fine-grained manner
  to the resource demands and playback the videos with appropriate QoE metrics as the user moves around with the group of tourists.<a href="#section-4-4" class="pilcrow">¶</a></p>
<p id="section-4-5">
 However, heavy-tailed nature of several  operational parameters make prediction-based  adaptation by ABR algorithms sub-optimal<span>[<a href="#ABR_2" class="cite xref">ABR_2</a>]</span>.
 This is because with such distributions, law of large numbers works too slowly, the mean of sample does not equal the mean of distribution,
 and as a result standard deviation and variance are unsuitable as metrics for such operational parameters <span>[<a href="#HEAVY_TAIL_1" class="cite xref">HEAVY_TAIL_1</a>]</span>,
 <span>[<a href="#HEAVY_TAIL_2" class="cite xref">HEAVY_TAIL_2</a>]</span>. Other subtle issues with
 these distributions include the "expectation paradox" <span>[<a href="#HEAVY_TAIL_1" class="cite xref">HEAVY_TAIL_1</a>]</span> where the longer we have waited for an event the
 longer we have to wait and the
 issue of mismatch between the size and count of events <span>[<a href="#HEAVY_TAIL_1" class="cite xref">HEAVY_TAIL_1</a>]</span>. This makes designing an algorithm for
 adaptation error-prone and challenging.
 Such operational parameters include but are not limited to buffer occupancy, throughput, client-server latency, and variable transmission
 times.In addition, edge devices and communication links  may fail and logical communication relationships between various software components
 change frequently as the user moves around with their AR device <span>[<a href="#UBICOMP" class="cite xref">UBICOMP</a>]</span>.<a href="#section-4-5" class="pilcrow">¶</a></p>
</section>
</div>
<div id="ArTraffic">
<section id="section-5">
      <h2 id="name-ar-network-traffic">
<a href="#section-5" class="section-number selfRef">5. </a><a href="#name-ar-network-traffic" class="section-name selfRef">AR Network Traffic</a>
      </h2>
<div id="traffic_workload">
<section id="section-5.1">
        <h3 id="name-traffic-workload">
<a href="#section-5.1" class="section-number selfRef">5.1. </a><a href="#name-traffic-workload" class="section-name selfRef">Traffic Workload</a>
        </h3>
<p id="section-5.1-1">
 As discussed earlier, the parameters that capture the characteristics of XR application behavior are heavy-tailed.
 Examples of such parameters include the distribution of arrival times between XR application invocation, the amount
 of data transferred, and the inter-arrival times of packets within a session.As a result, any traffic model based on
 such parameters are themselves heavy-tailed. Using
 these models to predict performance under alternative resource allocations by the network operator is challenging. For example, both uplink and downlink traffic to a UE device has parameters such as volume of XR data, burst time, and idle time that are heavy tailed.<a href="#section-5.1-1" class="pilcrow">¶</a></p>
<p id="section-5.1-2">
         <a href="#TABLE_1" class="auto internal xref">Table 1</a> below shows various XR applications and their associated throughput requirements <span>[<a href="#METRICS_1" class="cite xref">METRICS_1</a>]</span>. Our use case envisages a 6DoF video or point cloud and so will require 200 to 1000Mbps of bandwidth.
As seen from the table, the XR application such as our use case transmit a larger amount of data per unit time as compared to traditional video applications. As a result, issues arising out of heavy tailed parameters such as long-range dependent traffic <span>[<a href="#METRICS_2" class="cite xref">METRICS_2</a>]</span>, self-similar traffic <span>[<a href="#METRICS_3" class="cite xref">METRICS_3</a>]</span>, would be experienced at time scales of milliseconds and microseconds rather than hours or seconds. Additionally, burstiness at the time scale of tens of milliseconds due to multi-fractal spectrum of traffic will be experienced <span>[<a href="#METRICS_4" class="cite xref">METRICS_4</a>]</span>.
Long-range dependent traffic can have long bursts and various traffic parameters from widely separated time can show correlation. Self-similar traffic contains bursts at a wide range of time scales. Multi-fractal spectrum bursts for traffic summarizes the statistical distribution of local scaling exponents found in a traffic trace.
The operational consequences of XR traffic having characteristics such as long-range dependency, and self-similarity is that the edge servers to which multiple XR devices are connected wirelessly could face long bursts of traffic. In addition, multi-fractal spectrum burstiness at the scale of milli-seconds could induce jitter contributing to motion sickness.
The operators of edge servers will need to run a 'managed edge cloud service' <span>[<a href="#METRICS_5" class="cite xref">METRICS_5</a>]</span> to deal with the above problems. Functionalities that such a managed edge cloud service could operationally provide include dynamic placement of XR servers, mobility support and energy management <span>[<a href="#METRICS_6" class="cite xref">METRICS_6</a>]</span>. Providing Edge server support for the techniques being developed at the DETNET and RAW Working Groups at the IETF could guarantee performance of XR applications.<a href="#section-5.1-2" class="pilcrow">¶</a></p>
<span id="name-throughput-of-some-xr-appli"></span><div id="TABLE_1">
<table class="center" id="table-1">
          <caption>
<a href="#table-1" class="selfRef">Table 1</a>:
<a href="#name-throughput-of-some-xr-appli" class="selfRef">Throughput of some XR Applications</a>
          </caption>
<thead>
            <tr>
              <th class="text-left" rowspan="1" colspan="1"> Application</th>
              <th class="text-left" rowspan="1" colspan="1"> Throughput Required</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.1.1.1">Image and Workflow Downloading<a href="#section-5.1-3.2.1.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.1.2.1">1 Mbps<a href="#section-5.1-3.2.1.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.2.1.1">Video Conferencing<a href="#section-5.1-3.2.2.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.2.2.1">2 Mbps<a href="#section-5.1-3.2.2.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.3.1.1">3D Model and Data Visualization<a href="#section-5.1-3.2.3.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.3.2.1">2 to 20 Mbps<a href="#section-5.1-3.2.3.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.4.1.1">Two way Telepresence<a href="#section-5.1-3.2.4.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.4.2.1">5 to 25 Mbps<a href="#section-5.1-3.2.4.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.5.1.1">Current-Gen 360 degree video (4K)<a href="#section-5.1-3.2.5.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.5.2.1">10 to 50 Mbps<a href="#section-5.1-3.2.5.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.6.1.1">Next-Gen 360 degree video (8K, 90+ FPS, HDR, Stereoscopic)<a href="#section-5.1-3.2.6.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.6.2.1">50 to 200 Mbps<a href="#section-5.1-3.2.6.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.7.1.1">6DoF Video or Point Cloud<a href="#section-5.1-3.2.7.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.1-3.2.7.2.1">200 to 1000 Mbps<a href="#section-5.1-3.2.7.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
          </tbody>
        </table>
</div>
<p id="section-5.1-4">
 Thus, the provisioning of edge servers in terms of the number of servers, the topology, where to place them, the assignment of link capacity, CPUs and GPUs should keep the above factors in mind.<a href="#section-5.1-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="traffic_performance">
<section id="section-5.2">
        <h3 id="name-traffic-performance-metrics">
<a href="#section-5.2" class="section-number selfRef">5.2. </a><a href="#name-traffic-performance-metrics" class="section-name selfRef">Traffic Performance Metrics</a>
        </h3>
<p id="section-5.2-1">
   The performance requirements for AR/VR traffic have characteristics that need to be considered when operationalizing a network.
   We now discuss these characteristics.<a href="#section-5.2-1" class="pilcrow">¶</a></p>
<p id="section-5.2-2">The bandwidth requirements of XR applications are substantially higher than those of video based applications.<a href="#section-5.2-2" class="pilcrow">¶</a></p>
<p id="section-5.2-3">The latency requirements of XR applications have been studied recently  <span>[<a href="#AR_TRAFFIC" class="cite xref">AR_TRAFFIC</a>]</span> .The following issues were identified.:<a href="#section-5.2-3" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.2-4.1">The uploading of data from an AR device to a remote server for processing dominates the end-to-end latency.<a href="#section-5.2-4.1" class="pilcrow">¶</a>
</li>
          <li class="normal" id="section-5.2-4.2"> A lack of visual features in the grid environment can cause increased latencies as the AR device
    uploads additional visual data for processing to the remote server.<a href="#section-5.2-4.2" class="pilcrow">¶</a>
</li>
          <li class="normal" id="section-5.2-4.3">AR applications tend to have large bursts that are separated by significant time gaps.<a href="#section-5.2-4.3" class="pilcrow">¶</a>
</li>
        </ul>
<p id="section-5.2-5">The packet loss rates in wireless links between XR devices and the Edge server can be as high as 2% or more  <span>[<a href="#WIRELESS_1" class="cite xref">WIRELESS_1</a>]</span>.<a href="#section-5.2-5" class="pilcrow">¶</a></p>
<p id="section-5.2-6"> Additionally, XR applications interact with each other on a time scale of a round-trip-time propagation
   and this must be considered when operationalizing a network.<a href="#section-5.2-6" class="pilcrow">¶</a></p>
<p id="section-5.2-7">
            The following <a href="#TABLE_2" class="auto internal xref">Table 2</a> <span>[<a href="#METRICS_6" class="cite xref">METRICS_6</a>]</span> shows a taxonomy of applications with their associated required response times and bandwidths. Response times can
be defined as the time interval between the end of a request submission and the end of the corresponding response from a system. If the XR device offloads a task to an edge server, the response time of the server is the round trip time from when a data packet is sent from the XR device until a response is received. Note that the required response time provides an upper bound on the sum of the time taken by computational tasks such as processing of scenes, generation of images and the round trip time. This response time depends only on the Quality of Service (QOS) required by an application. The response time is therefore independent of the underlying technology of the network and the time taken by the computational tasks.<a href="#section-5.2-7" class="pilcrow">¶</a></p>
<p id="section-5.2-8">
Our use case requires a response time of 20ms at most and preferably between 7-15ms as discussed earlier. The required bandwidth for our use case as discussed in section 5.2 is 200Mbps-1000Mbps.
Since our use case envisages multiple users running the XR applications on their devices, and connected to an edge server that is closest to them, these latency and bandwidth connections will grow linearly with the number of users. The operators should match the network provisioning to the maximum number of tourists that can be supported by a link to an edge server.<a href="#section-5.2-8" class="pilcrow">¶</a></p>
<span id="name-traffic-performance-metrics-"></span><div id="TABLE_2">
<table class="center" id="table-2">
          <caption>
<a href="#table-2" class="selfRef">Table 2</a>:
<a href="#name-traffic-performance-metrics-" class="selfRef">Traffic Performance Metrics of Selected XR Applications</a>
          </caption>
<thead>
            <tr>
              <th class="text-left" rowspan="1" colspan="1"> Application</th>
              <th class="text-left" rowspan="1" colspan="1"> Required Response Time</th>
              <th class="text-left" rowspan="1" colspan="1"> Expected Data Capacity</th>
              <th class="text-left" rowspan="1" colspan="1"> Possible Implementations/ Examples</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.1.1.1">Mobile AR based remote assistance with uncompressed 4K  (1920x1080 pixels) 120 fps HDR 10-bit real-time video stream<a href="#section-5.2-9.2.1.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.1.2.1">Less than 10 milliseconds<a href="#section-5.2-9.2.1.2.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.1.3.1">Greater than 7.5 Gbps<a href="#section-5.2-9.2.1.3.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.1.4.1">Assisting maintenance technicians, Industry 4.0 remote maintenance, remote assistance in robotics industry<a href="#section-5.2-9.2.1.4.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.2.1.1">Indoor and localized outdoor navigation<a href="#section-5.2-9.2.2.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.2.2.1">Less than 20 milliseconds<a href="#section-5.2-9.2.2.2.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.2.3.1">50 to 200 Mbps<a href="#section-5.2-9.2.2.3.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.2.4.1">Theme Parks, Shopping Malls, Archaeological Sites, Museum guidance<a href="#section-5.2-9.2.2.4.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.3.1.1">Cloud-based Mobile AR applications<a href="#section-5.2-9.2.3.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.3.2.1">Less than 50 milliseconds<a href="#section-5.2-9.2.3.2.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.3.3.1">50 to 100 Mbps<a href="#section-5.2-9.2.3.3.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-5.2-9.2.3.4.1">Google Live View, AR-enhanced Google Translate<a href="#section-5.2-9.2.3.4.1" class="pilcrow">¶</a></p>
</td>
            </tr>
          </tbody>
        </table>
</div>
</section>
</div>
</section>
</div>
<div id="iana">
<section id="section-6">
      <h2 id="name-iana-considerations">
<a href="#section-6" class="section-number selfRef">6. </a><a href="#name-iana-considerations" class="section-name selfRef">IANA Considerations</a>
      </h2>
<p id="section-6-1">
     This document has no IANA actions.<a href="#section-6-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="Sec">
<section id="section-7">
      <h2 id="name-security-considerations">
<a href="#section-7" class="section-number selfRef">7. </a><a href="#name-security-considerations" class="section-name selfRef">Security Considerations</a>
      </h2>
<p id="section-7-1">
     The security issues for the presented use case are similar to other streaming applications. This document itself introduces no new security issues.<a href="#section-7-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="ack">
<section id="section-8">
      <h2 id="name-acknowledgements">
<a href="#section-8" class="section-number selfRef">8. </a><a href="#name-acknowledgements" class="section-name selfRef">Acknowledgements</a>
      </h2>
<p id="section-8-1">
 Many Thanks to Spencer Dawkins, Rohit Abhishek, Jake Holland, Kiran Makhijani
 ,Ali Begen and Cullen Jennings for providing very helpful feedback suggestions and comments.<a href="#section-8-1" class="pilcrow">¶</a></p>
</section>
</div>
<section id="section-9">
      <h2 id="name-informative-references">
<a href="#section-9" class="section-number selfRef">9. </a><a href="#name-informative-references" class="section-name selfRef">Informative References</a>
      </h2>
<dl class="references">
<dt id="ABR_1">[ABR_1]</dt>
      <dd>
<span class="refAuthor">Mao, H.</span>, <span class="refAuthor">Netravali, R.</span>, and <span class="refAuthor">M. Alizadeh</span>, <span class="refTitle">"Neural Adaptive Video Streaming with Pensieve"</span>, <span class="seriesInfo">In Proceedings of the Conference of the ACM Special Interest Group on Data Communication, pp. 197-210</span>, <time datetime="2017" class="refDate">2017</time>. </dd>
<dd class="break"></dd>
<dt id="ABR_2">[ABR_2]</dt>
      <dd>
<span class="refAuthor">Yan, F.</span>, <span class="refAuthor">Ayers, H.</span>, <span class="refAuthor">Zhu, C.</span>, <span class="refAuthor">Fouladi, S.</span>, <span class="refAuthor">Hong, J.</span>, <span class="refAuthor">Zhang, K.</span>, <span class="refAuthor">Levis, P.</span>, and <span class="refAuthor">K. Winstein</span>, <span class="refTitle">"Learning in situ: a randomized experiment in video streaming"</span>, <span class="seriesInfo">In 17th USENIX Symposium  on Networked Systems Design and Implementation (NSDI 20), pp. 495-511</span>, <time datetime="2020" class="refDate">2020</time>. </dd>
<dd class="break"></dd>
<dt id="AR_TRAFFIC">[AR_TRAFFIC]</dt>
      <dd>
<span class="refAuthor">Apicharttrisorn, K.</span>, <span class="refAuthor">Balasubramanian, B.</span>, <span class="refAuthor">Chen, J.</span>, <span class="refAuthor">Sivaraj, R.</span>, <span class="refAuthor">Tsai, Y.</span>, <span class="refAuthor">Jana, R.</span>, <span class="refAuthor">Krishnamurthy, S.</span>, <span class="refAuthor">Tran, T.</span>, and <span class="refAuthor">Y. Zhou</span>, <span class="refTitle">"Characterization of Multi-User Augmented Reality over Cellular Networks"</span>, <span class="seriesInfo">In 17th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON), pp. 1-9. IEEE</span>, <time datetime="2020" class="refDate">2020</time>. </dd>
<dd class="break"></dd>
<dt id="AUGMENTED">[AUGMENTED]</dt>
      <dd>
<span class="refAuthor">Schmalstieg, D. S.</span> and <span class="refAuthor">T.H. Hollerer</span>, <span class="refTitle">"Augmented Reality"</span>, <span class="seriesInfo"> Addison Wesley</span>, <time datetime="2016" class="refDate">2016</time>. </dd>
<dd class="break"></dd>
<dt id="AUGMENTED_2">[AUGMENTED_2]</dt>
      <dd>
<span class="refAuthor">Azuma, R. T.</span>, <span class="refTitle">"A Survey of Augmented Reality."</span>, <span class="seriesInfo"> Presence:Teleoperators and Virtual Environments 6.4, pp. 355-385.</span>, <time datetime="1997" class="refDate">1997</time>. </dd>
<dd class="break"></dd>
<dt id="BATT_DRAIN">[BATT_DRAIN]</dt>
      <dd>
<span class="refAuthor">Seneviratne, S.</span>, <span class="refAuthor">Hu, Y.</span>, <span class="refAuthor">Nguyen, T.</span>, <span class="refAuthor">Lan, G.</span>, <span class="refAuthor">Khalifa, S.</span>, <span class="refAuthor">Thilakarathna, K.</span>, <span class="refAuthor">Hassan, M.</span>, and <span class="refAuthor">A. Seneviratne</span>, <span class="refTitle">"A survey of wearable devices and challenges."</span>, <span class="seriesInfo">In IEEE Communication Surveys and Tutorials, 19(4), p.2573-2620.</span>, <time datetime="2017" class="refDate">2017</time>. </dd>
<dd class="break"></dd>
<dt id="BLUR">[BLUR]</dt>
      <dd>
<span class="refAuthor">Kan, P.</span> and <span class="refAuthor">H. Kaufmann</span>, <span class="refTitle">"Physically-Based Depth of Field in Augmented Reality."</span>, <span class="seriesInfo">In Eurographics (Short Papers), pp. 89-92.</span>, <time datetime="2012" class="refDate">2012</time>. </dd>
<dd class="break"></dd>
<dt id="CLOUD">[CLOUD]</dt>
      <dd>
<span class="refAuthor">Corneo, L.</span>, <span class="refAuthor">Eder, M.</span>, <span class="refAuthor">Mohan, N.</span>, <span class="refAuthor">Zavodovski, A.</span>, <span class="refAuthor">Bayhan, S.</span>, <span class="refAuthor">Wong, W.</span>, <span class="refAuthor">Gunningberg, P.</span>, <span class="refAuthor">Kangasharju, J.</span>, and <span class="refAuthor">J. Ott</span>, <span class="refTitle">"Surrounded by the Clouds: A Comprehensive Cloud Reachability Study."</span>, <span class="seriesInfo">In Proceedings of the Web Conference 2021, pp. 295-304</span>, <time datetime="2021" class="refDate">2021</time>. </dd>
<dd class="break"></dd>
<dt id="DEV_HEAT_1">[DEV_HEAT_1]</dt>
      <dd>
<span class="refAuthor">LiKamWa, R.</span>, <span class="refAuthor">Wang, Z.</span>, <span class="refAuthor">Carroll, A.</span>, <span class="refAuthor">Lin, F.</span>, and <span class="refAuthor">L. Zhong</span>, <span class="refTitle">"Draining our Glass: An Energy and Heat characterization of Google Glass"</span>, <span class="seriesInfo">In Proceedings of 5th Asia-Pacific Workshop on Systems pp. 1-7</span>, <time datetime="2013" class="refDate">2013</time>. </dd>
<dd class="break"></dd>
<dt id="DEV_HEAT_2">[DEV_HEAT_2]</dt>
      <dd>
<span class="refAuthor">Matsuhashi, K.</span>, <span class="refAuthor">Kanamoto, T.</span>, and <span class="refAuthor">A. Kurokawa</span>, <span class="refTitle">"Thermal model and countermeasures for future smart glasses."</span>, <span class="seriesInfo">In Sensors, 20(5), p.1446.</span>, <time datetime="2020" class="refDate">2020</time>. </dd>
<dd class="break"></dd>
<dt id="EDGE_1">[EDGE_1]</dt>
      <dd>
<span class="refAuthor">Satyanarayanan, M.</span>, <span class="refTitle">"The Emergence of Edge Computing"</span>, <span class="seriesInfo">In Computer 50(1) pp. 30-39</span>, <time datetime="2017" class="refDate">2017</time>. </dd>
<dd class="break"></dd>
<dt id="EDGE_2">[EDGE_2]</dt>
      <dd>
<span class="refAuthor">Satyanarayanan, M.</span>, <span class="refAuthor">Klas, G.</span>, <span class="refAuthor">Silva, M.</span>, and <span class="refAuthor">S. Mangiante</span>, <span class="refTitle">"The Seminal Role of Edge-Native Applications"</span>, <span class="seriesInfo">In IEEE International Conference on Edge Computing (EDGE) pp. 33-40</span>, <time datetime="2019" class="refDate">2019</time>. </dd>
<dd class="break"></dd>
<dt id="EDGE_3">[EDGE_3]</dt>
      <dd>
<span class="refAuthor">Peterson, L.</span> and <span class="refAuthor">O. Sunay</span>, <span class="refTitle">"5G mobile networks: A systems approach."</span>, <span class="seriesInfo">In Synthesis Lectures on Network Systems.</span>, <time datetime="2020" class="refDate">2020</time>. </dd>
<dd class="break"></dd>
<dt id="GLB_ILLUM_1">[GLB_ILLUM_1]</dt>
      <dd>
<span class="refAuthor">Kan, P.</span> and <span class="refAuthor">H. Kaufmann</span>, <span class="refTitle">"Differential irradiance caching for fast high-quality light transport between virtual and real worlds."</span>, <span class="seriesInfo">In IEEE International Symposium on Mixed and Augmented Reality (ISMAR),pp. 133-141</span>, <time datetime="2013" class="refDate">2013</time>. </dd>
<dd class="break"></dd>
<dt id="GLB_ILLUM_2">[GLB_ILLUM_2]</dt>
      <dd>
<span class="refAuthor">Franke, T.</span>, <span class="refTitle">"Delta voxel cone tracing."</span>, <span class="seriesInfo">In IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp. 39-44</span>, <time datetime="2014" class="refDate">2014</time>. </dd>
<dd class="break"></dd>
<dt id="HEAVY_TAIL_1">[HEAVY_TAIL_1]</dt>
      <dd>
<span class="refAuthor">Crovella, M.</span> and <span class="refAuthor">B. Krishnamurthy</span>, <span class="refTitle">"Internet measurement: infrastructure, traffic and applications"</span>, <span class="seriesInfo">John Wiley and Sons Inc.</span>, <time datetime="2006" class="refDate">2006</time>. </dd>
<dd class="break"></dd>
<dt id="HEAVY_TAIL_2">[HEAVY_TAIL_2]</dt>
      <dd>
<span class="refAuthor">Taleb, N.</span>, <span class="refTitle">"The Statistical Consequences of Fat Tails"</span>, <span class="seriesInfo">STEM Academic Press</span>, <time datetime="2020" class="refDate">2020</time>. </dd>
<dd class="break"></dd>
<dt id="LENS_DIST">[LENS_DIST]</dt>
      <dd>
<span class="refAuthor">Fuhrmann, A.</span> and <span class="refAuthor">D. Schmalstieg</span>, <span class="refTitle">"Practical calibration procedures for augmented reality."</span>, <span class="seriesInfo">In Virtual Environments 2000, pp. 3-12. Springer, Vienna</span>, <time datetime="2000" class="refDate">2000</time>. </dd>
<dd class="break"></dd>
<dt id="METRICS_1">[METRICS_1]</dt>
      <dd>
<span class="refAuthor">ABI Research</span>, <span class="refTitle">"Augmented and Virtual Reality: The first Wave of Killer Apps."</span>, <span class="seriesInfo"> https://gsacom.com/paper/augmented-virtual-reality-first-wave-5g-killer-apps-qualcomm-abi-research/</span>, <time datetime="2017" class="refDate">2017</time>. </dd>
<dd class="break"></dd>
<dt id="METRICS_2">[METRICS_2]</dt>
      <dd>
<span class="refAuthor">Paxon, V.</span> and <span class="refAuthor">S. Floyd</span>, <span class="refTitle">"Wide Area Traffic: The Failure of Poisson Modelling."</span>, <span class="seriesInfo">In IEEE/ACM Transactions on Networking, pp.  226-244.</span>, <time datetime="1995" class="refDate">1995</time>. </dd>
<dd class="break"></dd>
<dt id="METRICS_3">[METRICS_3]</dt>
      <dd>
<span class="refAuthor">Willinger, W.</span>, <span class="refAuthor">Taqqu, M.S.</span>, <span class="refAuthor">Sherman, R.</span>, and <span class="refAuthor">D.V. Wilson</span>, <span class="refTitle">"Self-Similarity Through High Variability: Statistical Analysis and Ethernet LAN Traffic at Source Level."</span>, <span class="seriesInfo">In IEEE/ACM Transactions on Networking, pp.  71-86.</span>, <time datetime="1997" class="refDate">1997</time>. </dd>
<dd class="break"></dd>
<dt id="METRICS_4">[METRICS_4]</dt>
      <dd>
<span class="refAuthor">Gilbert, A.C.</span>, <span class="refTitle">"Multiscale Analysis and Data Networks."</span>, <span class="seriesInfo">In Applied and Computational Harmonic Analysis, pp.  185-202.</span>, <time datetime="2001" class="refDate">2001</time>. </dd>
<dd class="break"></dd>
<dt id="METRICS_5">[METRICS_5]</dt>
      <dd>
<span class="refAuthor">Beyer, B.</span>, <span class="refAuthor">Jones, C.</span>, <span class="refAuthor">Petoff, J.</span>, and <span class="refAuthor">N.R. Murphy</span>, <span class="refTitle">"Site Reliability Engineering: How Google Runs Production Systems."</span>, <span class="seriesInfo"> O'Reilly Media, Inc.</span>, <time datetime="2016" class="refDate">2016</time>. </dd>
<dd class="break"></dd>
<dt id="METRICS_6">[METRICS_6]</dt>
      <dd>
<span class="refAuthor">Siriwardhana, Y.</span>, <span class="refAuthor">Porambage, P.</span>, <span class="refAuthor">Liyanage, M.</span>, and <span class="refAuthor">M. Ylianttila</span>, <span class="refTitle">"A survey on mobile augmented reality with 5G mobile edge computing: architectures, applications, and technical aspects."</span>, <span class="seriesInfo">In IEEE Communications Surveys and Tutorials, Vol 23, No. 2</span>, <time datetime="2021" class="refDate">2021</time>. </dd>
<dd class="break"></dd>
<dt id="NOISE">[NOISE]</dt>
      <dd>
<span class="refAuthor">Fischer, J.</span>, <span class="refAuthor">Bartz, D.</span>, and <span class="refAuthor">W. Straßer</span>, <span class="refTitle">"Enhanced visual realism by incorporating camera image effects."</span>, <span class="seriesInfo">In IEEE/ACM International Symposium on Mixed and Augmented Reality, pp. 205-208.</span>, <time datetime="2006" class="refDate">2006</time>. </dd>
<dd class="break"></dd>
<dt id="OCCL_1">[OCCL_1]</dt>
      <dd>
<span class="refAuthor">Breen, D.E.</span>, <span class="refAuthor">Whitaker, R.T.</span>, and <span class="refAuthor">M. Tuceryan</span>, <span class="refTitle">"Interactive Occlusion and automatic object placementfor augmented reality"</span>, <span class="seriesInfo">In Computer Graphics Forum, vol. 15, no. 3 , pp. 229-238,Edinburgh, UK: Blackwell Science Ltd</span>, <time datetime="1996" class="refDate">1996</time>. </dd>
<dd class="break"></dd>
<dt id="OCCL_2">[OCCL_2]</dt>
      <dd>
<span class="refAuthor">Zheng, F.</span>, <span class="refAuthor">Schmalstieg, D.</span>, and <span class="refAuthor">G. Welch</span>, <span class="refTitle">"Pixel-wise closed-loop registration in video-based augmented reality"</span>, <span class="seriesInfo">In IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp. 135-143</span>, <time datetime="2014" class="refDate">2014</time>. </dd>
<dd class="break"></dd>
<dt id="OCCL_3">[OCCL_3]</dt>
      <dd>
<span class="refAuthor">Lang, B.</span>, <span class="refTitle">"Oculus Shares 5 Key Ingredients for Presence in Virtual Reality."</span>, <span class="seriesInfo"> https://www.roadtovr.com/oculus-shares-5-key-ingredients-for-presence-in-virtual-reality/</span>, <time datetime="2014" class="refDate">2014</time>. </dd>
<dd class="break"></dd>
<dt id="PER_SENSE">[PER_SENSE]</dt>
      <dd>
<span class="refAuthor">Mania, K.</span>, <span class="refAuthor">Adelstein, B.D.</span>, <span class="refAuthor">Ellis, S.R.</span>, and <span class="refAuthor">M.I. Hill</span>, <span class="refTitle">"Perceptual sensitivity to head tracking latency in virtual environments with varying degrees of scene complexity."</span>, <span class="seriesInfo">In Proceedings of the 1st Symposium on Applied perception in graphics and visualization pp. 39-47.</span>, <time datetime="2004" class="refDate">2004</time>. </dd>
<dd class="break"></dd>
<dt id="PHOTO_REG">[PHOTO_REG]</dt>
      <dd>
<span class="refAuthor">Liu, Y.</span> and <span class="refAuthor">X. Granier</span>, <span class="refTitle">"Online tracking of outdoor lighting variations for augmented reality with moving cameras"</span>, <span class="seriesInfo">In IEEE Transactions on visualization and computer graphics, 18(4), pp.573-580</span>, <time datetime="2012" class="refDate">2012</time>. </dd>
<dd class="break"></dd>
<dt id="PREDICT">[PREDICT]</dt>
      <dd>
<span class="refAuthor">Buker, T. J.</span>, <span class="refAuthor">Vincenzi, D.A.</span>, and <span class="refAuthor">J.E. Deaton</span>, <span class="refTitle">"The effect of apparent latency on simulator sickness while using a see-through helmet-mounted display: Reducing apparent latency with predictive compensation.."</span>, <span class="seriesInfo">In Human factors 54.2, pp. 235-249.</span>, <time datetime="2012" class="refDate">2012</time>. </dd>
<dd class="break"></dd>
<dt id="REG">[REG]</dt>
      <dd>
<span class="refAuthor">Holloway, R. L.</span>, <span class="refTitle">"Registration error analysis for augmented reality."</span>, <span class="seriesInfo">In Presence:Teleoperators and Virtual Environments 6.4, pp. 413-432.</span>, <time datetime="1997" class="refDate">1997</time>. </dd>
<dd class="break"></dd>
<dt id="RFC2119">[RFC2119]</dt>
      <dd>
<span class="refAuthor">Bradner, S.</span>, <span class="refTitle">"Key words for use in RFCs to Indicate Requirement Levels"</span>, <span class="seriesInfo">BCP 14</span>, <span class="seriesInfo">RFC 2119</span>, <span class="seriesInfo">DOI 10.17487/RFC2119</span>, <time datetime="1997-03" class="refDate">March 1997</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc2119">https://www.rfc-editor.org/info/rfc2119</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="SLAM_1">[SLAM_1]</dt>
      <dd>
<span class="refAuthor">Ventura, J.</span>, <span class="refAuthor">Arth, C.</span>, <span class="refAuthor">Reitmayr, G.</span>, and <span class="refAuthor">D. Schmalstieg</span>, <span class="refTitle">"A minimal solution to the generalized pose-and-scale problem"</span>, <span class="seriesInfo">In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 422-429</span>, <time datetime="2014" class="refDate">2014</time>. </dd>
<dd class="break"></dd>
<dt id="SLAM_2">[SLAM_2]</dt>
      <dd>
<span class="refAuthor">Sweeny, C.</span>, <span class="refAuthor">Fragoso, V.</span>, <span class="refAuthor">Hollerer, T.</span>, and <span class="refAuthor">M. Turk</span>, <span class="refTitle">"A scalable solution to the generalized pose and scale problem"</span>, <span class="seriesInfo">In European Conference on Computer Vision, pp. 16-31</span>, <time datetime="2014" class="refDate">2014</time>. </dd>
<dd class="break"></dd>
<dt id="SLAM_3">[SLAM_3]</dt>
      <dd>
<span class="refAuthor">Gauglitz, S.</span>, <span class="refAuthor">Sweeny, C.</span>, <span class="refAuthor">Ventura, J.</span>, <span class="refAuthor">Turk, M.</span>, and <span class="refAuthor">T. Hollerer</span>, <span class="refTitle">"Model estimation and selection towards unconstrained real-time tracking and mapping"</span>, <span class="seriesInfo">In IEEE transactions on visualization and computer graphics, 20(6), pp. 825-838</span>, <time datetime="2013" class="refDate">2013</time>. </dd>
<dd class="break"></dd>
<dt id="SLAM_4">[SLAM_4]</dt>
      <dd>
<span class="refAuthor">Pirchheim, C.</span>, <span class="refAuthor">Schmalstieg, D.</span>, and <span class="refAuthor">G. Reitmayr</span>, <span class="refTitle">"Handling pure camera rotation in keyframe-based SLAM"</span>, <span class="seriesInfo">In 2013 IEEE international symposium on mixed and augmented reality (ISMAR), pp. 229-238</span>, <time datetime="2013" class="refDate">2013</time>. </dd>
<dd class="break"></dd>
<dt id="UBICOMP">[UBICOMP]</dt>
      <dd>
<span class="refAuthor">Bardram, J.</span> and <span class="refAuthor">A. Friday</span>, <span class="refTitle">"Ubiquitous Computing Systems"</span>, <span class="seriesInfo">In Ubiquitous Computing Fundamentals pp. 37-94. CRC Press</span>, <time datetime="2009" class="refDate">2009</time>. </dd>
<dd class="break"></dd>
<dt id="URLLC">[URLLC]</dt>
      <dd>
<span class="refAuthor">3GPP</span>, <span class="refTitle">"3GPP TR 23.725: Study on enhancement of Ultra-Reliable Low-Latency Communication (URLLC) support in the 5G Core network (5GC)."</span>, <span class="seriesInfo"> https://portal.3gpp.org/desktopmodules/Specifications/               SpecificationDetails.aspx?specificationId=3453</span>, <time datetime="2019" class="refDate">2019</time>. </dd>
<dd class="break"></dd>
<dt id="VIS_INTERFERE">[VIS_INTERFERE]</dt>
      <dd>
<span class="refAuthor">Kalkofen, D.</span>, <span class="refAuthor">Mendez, E.</span>, and <span class="refAuthor">D. Schmalstieg</span>, <span class="refTitle">"Interactive focus and context visualization for augmented reality."</span>, <span class="seriesInfo">In 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, pp. 191-201.</span>, <time datetime="2007" class="refDate">2007</time>. </dd>
<dd class="break"></dd>
<dt id="WIRELESS_1">[WIRELESS_1]</dt>
      <dd>
<span class="refAuthor">Balachandran, A.</span>, <span class="refAuthor">Voelker, G.M.</span>, <span class="refAuthor">Bahl, P.</span>, and <span class="refAuthor">P.V. Rangan</span>, <span class="refTitle">"Characterizing user behavior and network performance in a public wireless LAN."</span>, <span class="seriesInfo">In Proceedings of the 2002 ACM SIGMETRICS international conference on Measurement and modeling of computer systems, pp.  195-205.</span>, <time datetime="2002" class="refDate">2002</time>. </dd>
<dd class="break"></dd>
<dt id="XR">[XR]</dt>
    <dd>
<span class="refAuthor">3GPP</span>, <span class="refTitle">"3GPP TR 26.928: Extended Reality (XR) in 5G."</span>, <span class="seriesInfo"> https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3534</span>, <time datetime="2020" class="refDate">2020</time>. </dd>
<dd class="break"></dd>
</dl>
</section>
<div id="authors-addresses">
<section id="appendix-A">
      <h2 id="name-authors-addresses">
<a href="#name-authors-addresses" class="section-name selfRef">Authors' Addresses</a>
      </h2>
<address class="vcard">
        <div dir="auto" class="left"><span class="fn nameRole">Renan Krishna</span></div>
<div dir="auto" class="left"><span class="org">InterDigital Europe Limited</span></div>
<div dir="auto" class="left"><span class="street-address">64, Great Eastern Street</span></div>
<div dir="auto" class="left"><span class="locality">London</span></div>
<div dir="auto" class="left"><span class="postal-code">EC2A 3QR</span></div>
<div dir="auto" class="left"><span class="country-name">United Kingdom</span></div>
<div class="email">
<span>Email:</span>
<a href="mailto:renan.krishna@interdigital.com" class="email">renan.krishna@interdigital.com</a>
</div>
</address>
<address class="vcard">
        <div dir="auto" class="left"><span class="fn nameRole">Akbar Rahman</span></div>
<div dir="auto" class="left"><span class="org">Ericsson</span></div>
<div dir="auto" class="left"><span class="street-address">349 Terry Fox Drive</span></div>
<div dir="auto" class="left">
<span class="locality">Ottawa Ontario</span>  <span class="postal-code">K2K 2V6</span>
</div>
<div dir="auto" class="left"><span class="country-name">Canada</span></div>
<div class="email">
<span>Email:</span>
<a href="mailto:Akbar.Rahman@ericsson.com" class="email">Akbar.Rahman@ericsson.com</a>
</div>
</address>
</section>
</div>
<script>const toc = document.getElementById("toc");
toc.querySelector("h2").addEventListener("click", e => {
  toc.classList.toggle("active");
});
toc.querySelector("nav").addEventListener("click", e => {
  toc.classList.remove("active");
});
</script>
</body>
</html>
